{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/htk/.pyenv/versions/3.6.4/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, UpSampling2D,  Dense, Dropout,Activation, Flatten,Conv2D ,MaxPooling2D\n",
    "from keras.models import Model\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.utils import plot_model,np_utils\n",
    "import numpy as np\n",
    "import keras\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashon_minstのデータ読み込み\n",
    "- 学習データと教師データの読み込み\n",
    "- 教師データをone-hotに変換\n",
    "- 学習データを正規化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "encord = 32\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype(\"float32\")\n",
    "x_test = x_test.astype(\"float32\")\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "\n",
    "x_train /=255\n",
    "x_test /=255\n",
    "print(x_train.shape)\n",
    "x_train = np.reshape(x_train,(len(x_train),28,28,1))\n",
    "x_test = np.reshape(x_test,(len(x_test),28,28,1))\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ニューラルネットワークの構築\n",
    "- 入力層 (28 28 1)\n",
    "- 出力層 (28,28,1) (10)\n",
    "- autoencoderと認識のmulti_task_learningを行った\n",
    "- 活性化関数 relu sigmoid softmax\n",
    "- 勾配法 adam\n",
    "- 損失関数 binary_crossentropy categorical_crossentropy\n",
    "<img src=\"encorder.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(shape=(28,28,1))\n",
    "\n",
    "x = Conv2D(16,(3,3),padding=\"same\",activation=\"relu\")(input_img)\n",
    "x = MaxPooling2D((2,2),padding=\"same\")(x)\n",
    "x = Conv2D(8,(3,3),padding=\"same\",activation=\"relu\")(x)\n",
    "x = MaxPooling2D((2,2),padding=\"same\")(x)\n",
    "x = Conv2D(8,(3,3),padding=\"same\",activation=\"relu\")(x)\n",
    "flat = Flatten()(x)\n",
    "drop = Dropout(0.5)(flat)\n",
    "dense1 = Dense(50,activation=\"relu\",name=\"dense1\")(drop) \n",
    "dense2 = Dense(30,activation=\"sigmoid\",name=\"dense2\")(dense1) \n",
    "dense = Dense(10,activation=\"sigmoid\",name=\"dense\")(dense2) \n",
    "x = UpSampling2D((2,2))(x)\n",
    "x = Conv2D(8,(3,3),padding=\"same\",activation=\"relu\")(x)\n",
    "x = UpSampling2D((2,2))(x)\n",
    "x = Conv2D(8,(3,3),padding=\"same\",activation=\"relu\")(x)\n",
    "decode = Conv2D(1,(3,3),padding=\"same\",activation=\"sigmoid\",name=\"decode\")(x)\n",
    "output=[decode,dense]\n",
    "encorder = Model(inputs=input_img,outputs=output)\n",
    "encorder.load_weights(\"encord.h5\")\n",
    "plot_model(encorder,to_file=\"encorder.png\",show_shapes=True)\n",
    "\n",
    "encorder.compile(optimizer=\"adam\",\n",
    "                 loss={\"decode\":\"binary_crossentropy\",\n",
    "                       \"dense\":\"categorical_crossentropy\"},\n",
    "                       metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習結果\n",
    "<img src=\"fashion_mnist.png\">\n",
    "- autoencoder出力結果\n",
    "<img src=\"autencorde_fashion_mnist.png\">\n",
    "- 認識率  89%\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfit = encorder.fit(x_train,{\"decode\":x_train,\\n                            \"dense\":y_train},\\n                            epochs=20,\\n                            batch_size=124,\\n                            shuffle=True,\\n                            validation_data=(x_test,{\"decode\":x_test,\\n                            \"dense\":y_test}))\\nencorder.save_weights(\"encord.h5\")\\nprint(fit.history.keys())\\n\\nfig, (axL, axR) = plt.subplots(ncols=2, figsize=(10,4))\\n\\n# loss\\ndef plot_history_loss(fit):\\n    # Plot the loss in the history\\n    axL.plot(fit.history[\\'dense_loss\\'],label=\"loss for training\")\\n    axL.plot(fit.history[\\'val_dense_loss\\'],label=\"loss for validation\")\\n    axL.set_title(\\'model loss\\')\\n    axL.set_xlabel(\\'epoch\\')\\n    axL.set_ylabel(\\'loss\\')\\n    axL.legend(loc=\\'upper right\\')\\n\\n# acc\\ndef plot_history_acc(fit):\\n    # Plot the loss in the history\\n    axR.plot(fit.history[\\'dense_acc\\'],label=\"loss for training\")\\n    axR.plot(fit.history[\\'val_dense_acc\\'],label=\"loss for validation\")\\n    axR.set_title(\\'model accuracy\\')\\n    axR.set_xlabel(\\'epoch\\')\\n    axR.set_ylabel(\\'accuracy\\')\\n    axR.legend(loc=\\'upper right\\')\\n\\nplot_history_loss(fit)\\nplot_history_acc(fit)\\nfig.savefig(\\'./fashion_mnist.png\\')\\nplt.close()\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "fit = encorder.fit(x_train,{\"decode\":x_train,\n",
    "                            \"dense\":y_train},\n",
    "                            epochs=20,\n",
    "                            batch_size=124,\n",
    "                            shuffle=True,\n",
    "                            validation_data=(x_test,{\"decode\":x_test,\n",
    "                            \"dense\":y_test}))\n",
    "encorder.save_weights(\"encord.h5\")\n",
    "print(fit.history.keys())\n",
    "\n",
    "fig, (axL, axR) = plt.subplots(ncols=2, figsize=(10,4))\n",
    "\n",
    "# loss\n",
    "def plot_history_loss(fit):\n",
    "    # Plot the loss in the history\n",
    "    axL.plot(fit.history['dense_loss'],label=\"loss for training\")\n",
    "    axL.plot(fit.history['val_dense_loss'],label=\"loss for validation\")\n",
    "    axL.set_title('model loss')\n",
    "    axL.set_xlabel('epoch')\n",
    "    axL.set_ylabel('loss')\n",
    "    axL.legend(loc='upper right')\n",
    "\n",
    "# acc\n",
    "def plot_history_acc(fit):\n",
    "    # Plot the loss in the history\n",
    "    axR.plot(fit.history['dense_acc'],label=\"loss for training\")\n",
    "    axR.plot(fit.history['val_dense_acc'],label=\"loss for validation\")\n",
    "    axR.set_title('model accuracy')\n",
    "    axR.set_xlabel('epoch')\n",
    "    axR.set_ylabel('accuracy')\n",
    "    axR.legend(loc='upper right')\n",
    "\n",
    "plot_history_loss(fit)\n",
    "plot_history_acc(fit)\n",
    "fig.savefig('./fashion_mnist.png')\n",
    "plt.close()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 19s 2ms/step\n",
      "[[875.   0.  13.  15.   4.   1.  83.   0.   9.   0.]\n",
      " [  2. 974.   0.  18.   2.   0.   3.   0.   1.   0.]\n",
      " [ 12.   0. 842.   7.  75.   0.  62.   0.   2.   0.]\n",
      " [ 25.   3.   8. 892.  35.   0.  36.   0.   1.   0.]\n",
      " [  1.   1.  86.  27. 824.   0.  60.   0.   1.   0.]\n",
      " [  0.   0.   0.   0.   0. 975.   0.  13.   1.  11.]\n",
      " [150.   1.  77.  21.  73.   0. 666.   0.  12.   0.]\n",
      " [  0.   0.   0.   0.   0.   7.   0. 970.   0.  23.]\n",
      " [  3.   1.   3.   1.   4.   3.   1.   2. 981.   1.]\n",
      " [  0.   0.   0.   0.   0.   4.   1.  32.   0. 963.]]\n"
     ]
    }
   ],
   "source": [
    "result = encorder.predict(x_test,verbose=1)\n",
    "#print(encorder.evaluate(x_test,{\"decode\":x_test,\"dense\":y_test}))\n",
    "i = 0\n",
    "a=0\n",
    "score = np.zeros((10,10))\n",
    "\n",
    "for i,n in enumerate(result[1]):\n",
    "    if np.argmax(n)==np.argmax(y_test[i]):\n",
    "       pass\n",
    "    score[np.argmax(y_test[i]),np.argmax(n)] +=1\n",
    "print(score)\n",
    "#for i,predict in enumerate(score[0:1000]):\n",
    "#    y = np.array(score[1][i])\n",
    "img = np.array(result[0][2])\n",
    "img = np.reshape(img,(28,28))\n",
    "\n",
    "Image.fromarray(np.uint8(img*255)).save(\"autencorde_fashion_mnist.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 考察\n",
    "- mnistに比べるとfashonmnistは正解率が下がる傾向があった\n",
    "- 層の最適化やfine_tuningを行っていないため、正解率向上余地はある\n",
    "- mutli_task_learnigを行ったが共有層は問題なくうごいた\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
